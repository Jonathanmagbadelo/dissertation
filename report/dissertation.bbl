\begin{thebibliography}{}

\bibitem[Bengio et~al., 2003]{Bengio2003}
Bengio, Y., Ducharme, R., Vincent, P., and Janvin, C. (2003).
\newblock A neural probabilistic language model.
\newblock {\em J. Mach. Learn. Res.}, 3:1137--1155.

\bibitem[Chun Pui~Tang, 2018]{Pui2018}
Chun Pui~Tang, Ka Long~Chui, Y. K. Y. Z. Z. K. H.~W. (2018).
\newblock Music genre classification using a hierarchical long short term
  memory (lstm) model.

\bibitem[Corinna~Cortes, 1995]{Cortes1995}
Corinna~Cortes, V.~V. (1995).
\newblock Support-vector networks.

\bibitem[Dai and Le, 2015]{Dai2015a}
Dai, A.~M. and Le, Q.~V. (2015).
\newblock Semi-supervised sequence learning.

\bibitem[Duchi et~al., 2011]{Duchi2011}
Duchi, J., Hazan, E., and Singer, Y. (2011).
\newblock Adaptive subgradient methods for online learning and stochastic
  optimization.
\newblock {\em J. Mach. Learn. Res.}, 12:2121--2159.

\bibitem[Edwards and Rap, 2009]{Edwards2009}
Edwards, P. and Rap, K. (2009).
\newblock {\em How to Rap}.
\newblock Chicago Review Press, Incorporated.

\bibitem[Harris, 1954]{Harris1954}
Harris, Z.~S. (1954).
\newblock Distributional structure.
\newblock {\em Word}, 10(2-3):146--162.

\bibitem[Hochreiter and Schmidhuber, 1997]{Hochreiter1997}
Hochreiter, S. and Schmidhuber, J. (1997).
\newblock Long short-term memory.
\newblock {\em Neural computation}, 9(8):1735--1780.

\bibitem[Irvin et~al., 2016]{Irvin2016}
Irvin, J., Chartock, E., and Hollander, N. (2016).
\newblock Recurrent neural networks with attention for genre classification.

\bibitem[Joachims, 1998]{Joachims1998}
Joachims, T. (1998).
\newblock Text categorization with support vector machines: Learning with many
  relevant features.
\newblock In {\em European conference on machine learning}, pages 137--142.
  Springer.

\bibitem[Katz, 1987]{Katz1987}
Katz, S. (1987).
\newblock Estimation of probabilities from sparse data for the language model
  component of a speech recognizer.
\newblock {\em IEEE Transactions on Acoustics, Speech, and Signal Processing},
  35(3):400--401.

\bibitem[Lewis et~al., 2004]{Lewis2004}
Lewis, D.~D., Yang, Y., Rose, T.~G., and Li, F. (2004).
\newblock Rcv1: A new benchmark collection for text categorization research.

\bibitem[Manning et~al., 2008]{Manning2008}
Manning, C.~D., Raghavan, P., and Sch\"{u}tze, H. (2008).
\newblock {\em Introduction to Information Retrieval}.
\newblock Cambridge University Press, New York, NY, USA.

\bibitem[McCrum, 2011]{McCrum2011}
McCrum, R. (2011).
\newblock {\em The Story of English}.
\newblock BBC books. Faber \& Faber.

\bibitem[Mikolov et~al., 2013a]{Mikolov2013}
Mikolov, T., Chen, K., Corrado, G., and Dean, J. (2013a).
\newblock Efficient estimation of word representations in vector space.
\newblock {\em arXiv preprint arXiv:1301.3781}.

\bibitem[Mikolov et~al., 2010]{Mikolov2010}
Mikolov, T., Karafi{\'a}t, M., Burget, L., {\v{C}}ernock{\`y}, J., and
  Khudanpur, S. (2010).
\newblock Recurrent neural network based language model.
\newblock In {\em Eleventh annual conference of the international speech
  communication association}.

\bibitem[Mikolov et~al., 2013b]{Mikolov2013a}
Mikolov, T., Sutskever, I., Chen, K., Corrado, G.~S., and Dean, J. (2013b).
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In {\em Advances in neural information processing systems}, pages
  3111--3119.

\bibitem[Pennington et~al., 2014]{Pennington2014}
Pennington, J., Socher, R., and Manning, C. (2014).
\newblock Glove: Global vectors for word representation.
\newblock In {\em Proceedings of the 2014 conference on empirical methods in
  natural language processing (EMNLP)}, pages 1532--1543.

\bibitem[Potash et~al., 2015]{Potash2015}
Potash, P., Romanov, A., and Rumshisky, A. (2015).
\newblock Ghostwriter: Using an lstm for automatic rap lyric generation.
\newblock pages 1919--1924.

\bibitem[Qi et~al., 2018]{Qi2018}
Qi, Y., Singh~Sachan, D., Felix, M., Janani~Padmanabhan, S., and Neubig, G.
  (2018).
\newblock When and why are pre-trainedword embeddings useful for neural machine
  translation?

\bibitem[Rumelhart et~al., 1986]{Hinton1986}
Rumelhart, D.~E., Hinton, G.~E., Williams, R.~J., et~al. (1986).
\newblock Learning representations by back-propagating errors.
\newblock {\em Cognitive modeling}.

\bibitem[Rush et~al., 2015]{Rush2015}
Rush, A.~M., Chopra, S., and Weston, J. (2015).
\newblock A neural attention model for abstractive sentence summarization.
\newblock In {\em EMNLP}.

\bibitem[Srivastava et~al., 2014]{Srivastava2014}
Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov,
  R. (2014).
\newblock Dropout: A simple way to prevent neural networks from overfitting.
\newblock {\em Journal of Machine Learning Research}, 15:1929--1958.

\bibitem[Tian et~al., 2018]{Tian2018}
Tian, K., Zhang, T., and Zou, J. (2018).
\newblock Cover: Learning covariate-specific vector representations with tensor
  decompositions.
\newblock {\em arXiv preprint arXiv:1802.07839}.

\bibitem[Tsaptsinos, 2017]{Tsaptsinos2017}
Tsaptsinos, A. (2017).
\newblock Music genre classification by lyrics using a hierarchical attention
  network.

\bibitem[Yang et~al., 2016]{Yang2016}
Yang, Z., Yang, D., Dyer, C., He, X., Smola, A., and Hovy, E. (2016).
\newblock Hierarchical attention networks for document classification.
\newblock In {\em Proceedings of the 2016 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 1480--1489.

\bibitem[Zhang and Lapata, 2014]{Zhang2014}
Zhang, X. and Lapata, M. (2014).
\newblock Chinese poetry generation with recurrent neural networks.
\newblock In {\em Proceedings of the 2014 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 670--680.

\end{thebibliography}
