%-----------------------------------------------------
% Chapter: Prototype Implementation
%-----------------------------------------------------
\chapter{Implementation}
\label{chap:implementation}
Implementation of the project predominately utilised the  Python\footnote{https://www.python.org/} programming language. The motivation for using Python originated from prior familiarity with the language, and it's collection of machine learning and web development libraries which form two key components of the project. Though Python allows for relatively quick development, its known drawback of speed was a cause of concern.

\noindent
\newline
As stated in \autoref{chap:requirements_analysis}, in research, model training time is often neglected in favour of high performing models. As this project involves the creation of a prototype software application, it was important that the impact of model training time on overall development was minimal.

\noindent
\newline
This chapter describes the development process for implementing the CoVeR algorithm, the language and text classification models as well as the SONGIFAI web application. 

\section{Hardware Specification}
All implementation was completed on a personal machine. The hardware specifications for the machine are highlighted below

\begin{table}[h!]
	\centering
	\begin{tabular}{||c | c||} 
		\hline
		Hardware Component & Specification \\ [0.5ex] 
		\hline\hline
		CPU & Intel Core i7-8750H CPU @ 2.20GHz x 12 \\ 
		GPU & NVIDIA GeForce GTX 1050 Ti 4GB \\
		RAM & 16GB \\
		\hline
	\end{tabular}
	\caption[Hardware Specification]{Hardware specification for machine used throughout development}
	\label{table:1}
\end{table}
\section{Calculating Co-occurrence Statistics}
Many unsupervised NLP methods compute co-occurrence statistics before learning takes place. Typically, co-occurrence statistics, such as GloVe's word-word co-occurrence matrix contain sparse data, and computing them can often be a computationally more expensive task than the learning itself. The original GloVe paper describes this process as a \textit{'one-time upfront cost'}, with the assumption that selected corpora are static. Unfortunately, for many NLP pipelines such corpora are more dynamic in nature. For example, social data from online platforms such as Twitter\footnote{https://twitter.com/} are in constant flux and relying on pre-computed co-occurrence statistics to represent Twitter based word embeddings is sub-optimal. Compared to GloVe, computing the co-occurrence statistics for CoVeR has added complexity due to the transition from a co-occurrence matrix to a co-occurrence tensor.

\noindent
\newline
Methods for efficient computation of co-occurrence statistics include the usage of distributed computing techniques such as \textit{MapReduce}. MapReduce is a model for distributed computing which at its crux involves two functional processes: namely the mapper and the reducer. During the \textit{map} process, data is taken in as key/value pairs and transformed to intermediary key/value pairs as output. These are then passed to the \textit{reduce} process which aggregates data which share the same key. An example MapReduce process is walked through in \autoref{fig:fig14} below 

\begin{figure}[h]
	\includegraphics[width=14cm, height=6cm]{./figures/fig14}
	\centering
	\caption[MapReduce Word Count Example]{MapReduce word count example: }
	\label{fig:fig14}
\end{figure}

\noindent
\newline
\newline
Apache Spark is an open-source framework, written in Scala, for distributed computing and has recently emerged as the de-facto choice for big data processing over Apache Hadoop. Like Hadoop, Spark also supports the MapReduce programming paradigm but boasts features such as enhanced speed, a distributed data structure, as well as API's written in multiple programming languages. Spark uses a master/slave architecture to achieve distributed computing. The \textit{driver} acts as the master node and distributes tasks to many different worker nodes, also known as \textit{executors}, which each run their own JVM processes to execute tasks.

\begin{figure}[h]
	\includegraphics[width=12cm, height=6cm]{./figures/fig5}
	\centering
	\caption{High level view of the Spark Architecture. The spark context is where the main program is defined, which is then split into tasks to be completed via numerous executors.}
	\label{fig:fig5}
\end{figure}

\noindent
\newline
PySpark, a Python API for the Spark framework was initially used to both pre-process and calculate co-occurrence statistics for the dataset. 
Unfortunately, the overhead of collecting completed executor tasks to the driver as well as the cross language communication between Python and Scala made PySpark an unfavourable option for collecting co-occurrence statistics. A similar parallelised approach which avoided cross language communication involved the use of Python's multiprocessing module. This approach suffered from the restrictions of Pythons Global Interpreter Lock (GIL) which prevents shared access of Python objects across multiple threads. 

\noindent
\newline
Cython is a superset of the Python programming language which aims to provide C like performance whilst maintaining the ability to write Python like code. Native Python programs can experience major speed improvements using Cython because of its ability to compile Python to C code. Ultimately, calculating the co-occurrence statistics for CoVeR was achieved using Cython which provided major speed ups compared to the parallelised approaches outlined before. A comparison of the speed gain for computing co-occurrences can be seen in the figure below.

\begin{figure}[ht]
	\includegraphics[width=13cm, height=13cm]{./figures/fig15}
	\centering
	\caption[Co-occurrence benchmarks]{Benchmarks}
	\label{fig:fig15}
\end{figure}

\noindent
\newline
\section{CoVeR Implementation}
At time of writing, no public implementation of CoVeR is available. As a result and to meet the needs of this project, CoVeR was implemented from scratch using the PyTorch library. PyTorch is a Python library based on Torch, which supports Numpy like operations which can be accelerated through the GPU. All supporting code for the implementation can be found here: (LINK TO CODE)

\section{LSTM Implementations}
Implementation of both the neural language model and text classifier was done using Keras. Keras is a high level machine learning library written in Python, which runs on top of either Tensorflow or Theano. The motivation behind using Keras comes from its ease of use to quickly develop deep learning networks. In this project Keras is deployed using Tensorflow as a backend, specifically for its GPU capabilities.
\subsection{Language Model}
The structure for the language model can be seen in Figure X.X. The model consisted of an input layer, an embedding layer, a bidirectional LSTM, a dropout layer and finally a dense layer.
\subsection{Text Classifier}
The structure for the text classifier can be seen in Figure X.X. The model consisted of an input layer, an embedding layer, a bidirectional LSTM, a dropout layer and finally a dense layer.
\section{SONGIFAI}
\subsection{Architecture}
\subsubsection{Client Side}
For the client-side development of SONGIFGAI, a main requirement refers to the systems availability for web and mobile access. Being a prototype solution, it was important that the development was swift and well structured so that the research goals of the project were not hindered. To help achieve this, ReactJS was chosen as the front-end development framework.

\noindent
\newline
React is a Javascript framework for building user interfaces originally developed and maintained by Facebook. The main advantages of using React
\subsubsection{Server Side}
Requirements ... refer to a user of the system being able to save, load and edit their lyrics. Moreover for easy compatibility with the Keras generated models, another Python based library was preferred as the for the server side. To meet these conditions, Django was chosen as the development framework for the back-end of the system. Django is a python based web framework which follows the model-view-template (MVT) architectural pattern.
\subsection{Class Overview}