{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Cover Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = '/usr/bin/python3'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/usr/bin/python3'\n",
    "os.environ['PYTHONPATH'] = '$PYTHONPATH:/opt/training'\n",
    "os.chdir('/opt/training')\n",
    "\n",
    "spark_session = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Cover\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark_session.sparkContext.addPyFile(\"/opt/training/src/modelling/Cover.py\")\n",
    "spark_session.sparkContext.addPyFile(\"/opt/training/src/processing/utils.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modelling import Cover\n",
    "from src.processing import utils\n",
    "filename = '/opt/training/data/raw/lyrics.csv'\n",
    "column_name = 'Lyrics'\n",
    "cover = Cover.Cover(spark_session=spark_session, embedding_size=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "cover.import_data(filename)\n",
    "cover.fit_transform(column_name=column_name, min_occurrence_count=5, window_size=5)\n",
    "cover.build_co_occurrence_matrix()\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Time taken is {}\".format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+----+\n",
      "|age                       |type|\n",
      "+--------------------------+----+\n",
      "|[[2, 2] -> 2, [1, 2] -> 1]|one |\n",
      "|[[1, 2] -> 1]             |two |\n",
      "|[[2, 2] -> 3]             |one |\n",
      "|[[2, 2] -> 3]             |two |\n",
      "+--------------------------+----+\n",
      "\n",
      "+------+----+-----+\n",
      "|   key|type|value|\n",
      "+------+----+-----+\n",
      "|[1, 2]| two|    1|\n",
      "|[2, 2]| one|    5|\n",
      "|[2, 2]| two|    3|\n",
      "|[1, 2]| one|    1|\n",
      "+------+----+-----+\n",
      "\n",
      "[('two', [([1, 2], 'two', 1), ([2, 2], 'two', 3)]), ('one', [([2, 2], 'one', 5), ([1, 2], 'one', 1)])]\n",
      "([2, 2], [1, 2])\n",
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import MapType, StringType, IntegerType, StructType, StructField, ArrayType\n",
    "from pyspark.sql.functions import col, explode, sum as sum_ \n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"age\", MapType(ArrayType(IntegerType()), IntegerType()), False),\n",
    "    StructField(\"type\", StringType(), False)\n",
    "])\n",
    "\n",
    "df = spark_session.createDataFrame([({(1, 2): 1, (2 , 2): 2}, \"one\"), ({(1, 2): 1}, \"two\"), ({(2, 2): 3} , \"one\"), ({(2, 2): 3} , \"two\")], schema)\n",
    "\n",
    "df.show(10, False)\n",
    "\n",
    "t = df.select(explode(col(\"age\")), \"type\").groupBy(col(\"key\"), col(\"type\")).agg(sum_(\"value\").alias(\"value\"))\n",
    "\n",
    "t.show()\n",
    "\n",
    "x = t.select(\"value\", \"key\", \"type\").rdd.map(lambda x: (x.key, x.type, x.value)).groupBy(lambda x: x[1]).mapValues(list).collect()\n",
    "\n",
    "print(x)\n",
    "\n",
    "x = [zip(*y[1]) for y in x]\n",
    "\n",
    "\n",
    "index, genre, value = x[1]\n",
    "\n",
    "print(index)\n",
    "\n",
    "\n",
    "#MapType(ArrayType(IntegerType()), IntegerType())\n",
    "\n",
    "print(value)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
